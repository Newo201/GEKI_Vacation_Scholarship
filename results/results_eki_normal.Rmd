---
title: Generalised Ensemble Kalman Inversion - Multivariate Normal
output: github_document
---

```{r}
source('C:/Users/owenj/OneDrive/Uni/Vacation Scholarship/GEKI_Vacation_Scholarship/src/models/eki_normal.R')
```

```{r}
plot_eki_normal <- function(eki_result, true_params, prior_params) {
  
  alpha_particles <- eki_result$particles[, 1]
  alpha_sequence <- seq(min(alpha_particles), max(alpha_particles), 
                        length.out = 20)
  alpha_prior_density <- dnorm(alpha_sequence, mean = prior_params$alpha.mean, 
                               sd = prior_params$alpha.sd)
  true_alpha <- true_params$alpha
  sigma2_particles <- eki_result$particles[, 2]
  sigma2_sequence <- seq(min(sigma2_particles), max(sigma2_particles),
                         length.out = 20)
  sigma2_prior_density <- dnorm(sigma2_sequence, mean = prior_params$sigma2.mean, 
                                sd = prior_params$sigma2.sd)
  true_sigma2 <- log(true_params$sigma**2)
  
  par(mfrow = c(1, 2))
  
  hist(alpha_particles, freq = F, main = 'Alpha', xlab = '')
  lines(alpha_sequence, alpha_prior_density, col = 'blue')
  abline(v = true_alpha, col = 'red')
  hist(sigma2_particles, freq = F, main = 'Sigma2', xlab = '', ylab = '')
  lines(sigma2_sequence, sigma2_prior_density, col = 'blue')
  abline(v = true_sigma2, col = 'red')
}
```

```{r}
adaptive = TRUE
```

# Results For Multivariate Normal Model

## The Model

We assume that we have access to a single observation from a multivariate normal distribution $y \sim N(\alpha x, \sigma^2I)$ where $\alpha$ is a scalar and $x$ is a known vector.

I look at three variations of this model

-   The variance is known, but the mean is not $\theta = \alpha$

-   The mean is known, but the variance is not $\theta = \sigma^2$

-   Both parameters are unknown $\theta = (\alpha, \sigma^2)$.

I look at a range of combinations of $\alpha, x$ and $\sigma^2$, comparing against MCMC sampling. Of particular interest is how well GEKI is able to estimate the noise parameter, since previous EKI algorithms require the noise parameter to be known.

### Priors

In all combinations we draw from the same priors (if that parameter is considered unknown):

-   $\alpha \sim ~ N(0, 5^2)$

-   $\log(\sigma^2) \sim N(2, 1^2)$

```{r}
prior_params <- list(alpha.mean = 0, alpha.sd = 5, 
                     sigma2.mean = 2, sigma2.sd = 1)
```

### Output

For each variation of the model, I plot the EKI histograms of the particles against their prior. In the known mean, unknown variance case, I also plot the posterior since there is an analytical posterior in this special case. This serves as a check that the algorithm has been implemented correctly.

## Changing Number of Dimensions

In this experiment I keep $\alpha$ and $\sigma^2$ fixed at 2 and 4 respectively and let $x$ be a vector of 1s corresponding to 10, 50 and 100 dimensions. The purpose of this is to see how the EKI algorithm performs when the number of dimensions increases.

```{r}
num_dimensions <- c(10, 50, 100)
for (dimension in num_dimensions) {
  num_particles <- 4*dimension
  true_parameters <- list(alpha = 2, sigma = 2, x = rep(1, dimension))
  true_data <- likelihood_normal(true_parameters)
  eki_result <- eki_normal(num_particles, true_data, true_parameters, prior_params, adaptive = adaptive)
  plot_eki_normal(eki_result, true_parameters, prior_params)
}
```

Generally speaking, the model does reasonably well at estimating $\alpha$ but appears to under-estimate the noise parameter. As the number of dimensions increases, the distribution of $\alpha$ becomes more concentrated, but the distribution of $\sigma^2$ does not demonstrate any noticeable pattern.

## Changing $\alpha$

In this experiment, I keep $\sigma^2$ fixed at 4, make $x$ a 50-dimensional vector of 1s and change $\alpha$ from 0 to 10 in increments of 2. The purpose of this is to make sure that the EKI algorithm is accurate across of range of $\alpha$ and if it changes how the noise parameter is estimated.

```{r}
alpha_seq <- seq(0, 10, length.out = 6)
```

### Standard EKI

```{r}
num_dimensions <- 50
num_particles <- 4*num_dimensions
for (alpha in alpha_seq) {

  true_parameters <- list(alpha = alpha, sigma = 2, x = rep(1, num_dimensions))
  eki_result <- eki_normal(num_particles, true_parameters, prior_params, adaptive = adaptive)
  plot_eki_normal(eki_result, true_parameters, prior_params)
}
```

## Changing $\sigma^2$

```{r}
sigma_seq <- seq(2, 10, length.out = 5)
```

### Standard EKI

```{r}
num_dimensions <- 50
num_particles <- 4*num_dimensions
for (sigma in sigma_seq) {

  true_parameters <- list(alpha = 2, sigma = sigma, x = rep(1, num_dimensions))
  eki_result <- eki_normal(num_particles, true_parameters, prior_params, adaptive = adaptive)
  plot_eki_normal(eki_result, true_parameters, prior_params)
}
```

## Changing $x$

In this experiment I keep $\alpha$ and $\sigma^2$ fixed at 2 and 4 respectively and let $x$ be a 50 dimensional random vector.

### Standard EKI

```{r}
num_dimensions <- 50
x <- rnorm(50, mean = 1, sd = 1)
true_parameters <- list(alpha = 2, sigma = 2, x = x)
eki_result <- eki_normal(num_particles, true_parameters, prior_params)
plot_eki_normal(eki_result, true_parameters, prior_params)
```

## Changing Number of Particles

```{r}
num_dimensions <- 50
particle_seq <- c(100, 500, 1000) 
true_parameters <- list(alpha = 2, sigma = 5, x = rep(1, num_dimensions))

for (num_particles in particle_seq) {
  eki_result <- eki_normal(num_particles, true_parameters, prior_params)
  plot_eki_normal(eki_result, true_parameters, prior_params)
}
```
